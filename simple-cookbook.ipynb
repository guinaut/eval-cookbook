{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Multi-turn Evaluation Demo\n",
    "\n",
    "**ðŸŽ¯ Goal**:\n",
    "- Run a [multi-turn evaluation](https://docs.okareo.ai/docs/guides/multiturn_overview) in Okareo.\n",
    "- Provide a simple introduction to Okareo evaluations.\n",
    "\n",
    "**ðŸ“‹ Steps**:\n",
    "1. Upload a multi-turn scenario.\n",
    "2. Define a custom model to act as a Target in a multi-turn conversation.\n",
    "3. Run the evaluation using the scenario (1.) + model (2.) and checks for measuring behavioral adherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade okareo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Okareo client\n",
    "import os\n",
    "from okareo import Okareo\n",
    "\n",
    "OKAREO_API_KEY = os.environ.get(\"OKAREO_API_KEY\", \"<YOUR_OKAREO_API_KEY>\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"<YOUR_OPENAI_API_KEY>\")\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"<YOUR_OPENAI_API_KEY>\")\n",
    "print(f\"Using Okareo API key: {OKAREO_API_KEY}\")\n",
    "okareo = Okareo(OKAREO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a simple scenario. Each row of the `seed_data` should contain:\n",
    "\n",
    "- `input_`: a prompt used to direct the Driver.\n",
    "- `result`: a behavioral directive that we want the Target to adhere to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "from okareo_api_client.models.scenario_set_create import ScenarioSetCreate\n",
    "from okareo_api_client.models.seed_data import SeedData\n",
    "\n",
    "def random_string(length: int) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_letters, k=length))\n",
    "\n",
    "def persona_prompt(objective: str) -> str:\n",
    "    return f\"\"\"You are a black-belt in 6-sigma. You are talking to a co-pilot who is an expert in 6-sigma problem-solving and process improvement.\n",
    "Your goal is to have the co-pilot produce a clear and concise plan for each phase. Your approach is to provide the co-pilot with a clear problem statement.\n",
    "If the co-pilot does not understand the problem, it will ask you for clarification. Answer the questions.\n",
    "If the co-pilot provides a good starting point for the plan, then request the next phase of the plan.\n",
    "The range of actions you can take are listed below.\n",
    "When articulating the problem statement, always use the full problem statement provided below.\n",
    "NEVER DO THE CO-PILOT'S WORK FOR IT.\n",
    "\n",
    "Problem Statement:\n",
    "    {objective}\n",
    "\n",
    "Available Actions:\n",
    "    1. Use the provided Problem Statement as written to clearly and concisely request a plan.\n",
    "    2. Review each phase of the plan. If acceptable, request the next phase.\n",
    "    3. If an element in the plan is not acceptable, ASK A CLARIFYING QUESTION to understand the issue, then request a modification to the plan.\n",
    "    4. If the plan is complete, then say \"Plan complete\" and end the conversation.\n",
    "\"\"\"\n",
    "\n",
    "seeds = [\n",
    "    SeedData(\n",
    "        input_=persona_prompt(\"\"\"Our main competitor in the SaaS space recently announced their internal \"AI-Assist\" help desk resolved 60 percent of all IT issues without human intervention,\n",
    "    leading to a 40-point increase in their employee Net Promoter Score (eNPS) for IT support. In contrast, a well-known tech firm suffered a major data breach and\n",
    "    reputational damage last quarter when their GenAI support bot was tricked into leaking sensitive employee data. Our current IT help desk has a low 35 percent first-\n",
    "    contact resolution rate and a negative eNPS score, frustrating employees and tying up expensive engineering resources on basic support tasks, leaving us\n",
    "    inefficient and exposed to the same security vulnerabilities.\"\"\"),\n",
    "        result=\"\"\"Clear guidance and a structured approach to address the problem statement.\"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "scenario_set_create = ScenarioSetCreate(\n",
    "    name=f\"AnalyticsAIML - v0.5\",\n",
    "    seed_data=seeds,\n",
    "    \n",
    ")\n",
    "scenario = okareo.create_scenario_set(scenario_set_create)\n",
    "\n",
    "print(scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo.model_under_test import CustomMultiturnTarget, ModelInvocation\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "class BlackBeltDriver(CustomMultiturnTarget):\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def use_6sigma(self, last_msg: str, msg_history: list) -> str:\n",
    "        print(f\"6Sigma Message: {last_msg}\")\n",
    "        url = 'https://six-sigma-suite-frankshines.replit.app/api/chat/message'  # Example URL for testing\n",
    "        json_data = json.dumps({\n",
    "            \"message\": last_msg,  # Use the last message content\n",
    "            \"conversationHistory\": msg_history,\n",
    "        })\n",
    "        headers = {'Content-type': 'application/json' }\n",
    "        response = requests.post(url, data=json_data, headers=headers)\n",
    "\n",
    "        # Print the response body as JSON\n",
    "        result = response.json()[\"response\"]\n",
    "        print(f\"6Sigma Response: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def use_OpenAI(self, last_msg: str, msg_history: list) -> str:\n",
    "        print(f\"OpenAI Message: {last_msg}\")\n",
    "        openai = OpenAI(\n",
    "            base_url=\"https://proxy.okareo.com\",\n",
    "            default_headers={\"api-key\": OKAREO_API_KEY},\n",
    "            api_key = OPENAI_API_KEY\n",
    "        )\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=msg_history+[\n",
    "                {\"role\": \"user\", \"content\": last_msg}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        generated_text = response.choices[0].message.content.strip()\n",
    "        # Send the POST request\n",
    "        return generated_text\n",
    "    \n",
    "    def use_Gemini(self, last_msg: str, msg_history: list) -> str:\n",
    "        print(f\"Gemini Message: {last_msg}\")\n",
    "        openai = OpenAI(\n",
    "            base_url=\"https://proxy.okareo.com\",\n",
    "            default_headers={\"api-key\": OKAREO_API_KEY},\n",
    "            api_key = GEMINI_API_KEY\n",
    "        )\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gemini/gemini-1.5-pro-002\",\n",
    "            messages=msg_history+[\n",
    "                {\"role\": \"user\", \"content\": last_msg}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        generated_text = response.choices[0].message.content.strip()\n",
    "        # Send the POST request\n",
    "        return generated_text\n",
    "\n",
    "    def invoke(self, messages: list) -> ModelInvocation:\n",
    "        msg_history = []\n",
    "        last_msg = \"\"\n",
    "        if (len(messages) >= 2):\n",
    "            last_msg = messages[-1][\"content\"]\n",
    "            msg_history = messages[1:-1]  # Exclude the last message for processing\n",
    "            \n",
    "            result = self.use_6sigma(last_msg, msg_history)\n",
    "\n",
    "            return ModelInvocation(\n",
    "                result,\n",
    "                messages,\n",
    "                {}\n",
    "            )\n",
    "\n",
    "blackbelt_driver = BlackBeltDriver(\"BlackBeltDriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register a `MultiTurnDriver` using your CustomModel as the Target.\n",
    "\n",
    "We use the predefined [check](https://docs.okareo.ai/docs/getting-started/concepts/checks) called Behavior Adherence to evaluate how well the Target is adhereing to its  directive to only talk about WebBizz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo.model_under_test import GenerationModel, MultiTurnDriver, StopConfig\n",
    "\n",
    "multiturn_model = okareo.register_model(\n",
    "    name=\"Persona Behavior 2.3\",\n",
    "    model=MultiTurnDriver(\n",
    "        driver_temperature=1,\n",
    "        max_turns=7,\n",
    "        repeats=1,\n",
    "        #driver_model_id=\"gemini/gemini-1.5-pro-002\",\n",
    "        first_turn=\"driver\",\n",
    "        target=blackbelt_driver,\n",
    "        stop_check=StopConfig(check_name=\"DMAIC Complete\", stop_on=True)\n",
    "    ),\n",
    "    update=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a [Multiturn evaluation](https://docs.okareo.ai/docs/guides/multiturn_overview#step-5-run-an-evaluation) on the custom model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo_api_client.models.test_run_type import TestRunType\n",
    "\n",
    "\n",
    "evaluation = multiturn_model.run_test(\n",
    "    scenario=scenario,\n",
    "    name=\"Persona Behavior 2.3\",\n",
    "    test_run_type=TestRunType.MULTI_TURN,\n",
    "    checks=[\n",
    "        \"P1 Define Complete\", \n",
    "        \"P2 Measure Complete\", \n",
    "        \"P3 Analyze Complete\", \n",
    "        \"P4 Improve Complete\",\n",
    "        \"P5 Control Complete\",\n",
    "        \"DMAIC Planning Progress\", \n",
    "        \"Planning Complete\", \n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"See results in Okareo: {evaluation.app_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN UP\n",
    "\"\"\"\n",
    "{\n",
    "        \"id\": \"2628495a-9a22-47df-a2f4-22226aa96668\",\n",
    "        \"project_id\": \"8c69ab40-7e5e-4449-ad8c-f1e271cf62e6\",\n",
    "        \"mut_id\": \"4ae74abd-2b02-46d8-bc57-6d45674adf6d\",\n",
    "        \"scenario_set_id\": \"e904e39c-02f6-4f21-a77e-8b4d8b4f72c4\",\n",
    "        \"filter_group_id\": \"38e0d40c-931e-403a-9d97-5adc3d61e0fd\",\n",
    "        \"name\": \"GUI Test 2\",\n",
    "        \"tags\": [\n",
    "            \"multi-turn-eval\"\n",
    "        ],\n",
    "        \"type\": \"MULTI_TURN\",\n",
    "        \"start_time\": \"2025-06-04T05:16:43.203008\",\n",
    "        \"end_time\": \"2025-06-04T05:16:43.601439\",\n",
    "        \"test_data_point_count\": null,\n",
    "        \"model_metrics\": {},\n",
    "        \"error_matrix\": [],\n",
    "        \"status\": \"FAILED\",\n",
    "        \"progress\": 0,\n",
    "        \"app_link\": \"https://app.okareo.com/project/8c69ab40-7e5e-4449-ad8c-f1e271cf62e6/eval/2628495a-9a22-47df-a2f4-22226aa96668\"\n",
    "    },\n",
    "\"\"\"\n",
    "import requests\n",
    "import json\n",
    "\n",
    "okareo_headers = {\n",
    "    'Content-type': 'application/json',\n",
    "    \"api-key\": OKAREO_API_KEY, \n",
    "}\n",
    "find_url = 'https://api.okareo.com/v0/find_test_runs'  # Example URL for testing\n",
    "find_json_data = json.dumps({\n",
    "    \"project_id\": \"8c69ab40-7e5e-4449-ad8c-f1e271cf62e6\",\n",
    "})\n",
    "find_response = requests.post(find_url, data=find_json_data, headers=okareo_headers)\n",
    "\n",
    "# Print the response body as JSON\n",
    "result = find_response.json()\n",
    "failed_multi_turn_ids = []\n",
    "failed_id_str = \"\"\n",
    "item = 0\n",
    "for run in result:\n",
    "    if run[\"type\"] == \"MULTI_TURN\" and run[\"status\"] == \"FAILED\":\n",
    "        if item == 0:\n",
    "            failed_id_str += f\"test_run_ids={run['id']}\"\n",
    "        else:\n",
    "            failed_id_str += f\"&test_run_ids={run['id']}\"\n",
    "        item += 1\n",
    "        failed_multi_turn_ids.append(run[\"id\"])\n",
    "\n",
    "\n",
    "print(f\"{failed_id_str}\")\n",
    "delete_url = f\"https://api.okareo.com/v0/test_runs?{failed_id_str}\"\n",
    "find_json_data = json.dumps({\n",
    "    \"project_id\": \"8c69ab40-7e5e-4449-ad8c-f1e271cf62e6\",\n",
    "})\n",
    "delete_response = requests.delete(delete_url, headers=okareo_headers)\n",
    "print(f\"Response {delete_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
